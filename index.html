<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>LiveSearchbench â€” Realâ€‘time Search Evaluation</title>
  <meta name="description"
    content="A minimal, zero-build GitHub Pages site for a LiveSearchbench-style leaderboard and details." />
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    .striped tr:nth-child(even) {
      background: rgba(0, 0, 0, 0.03);
    }

    .striped tr:hover {
      background: rgba(59, 130, 246, 0.05);
    }

    .rank-1 {
      background: linear-gradient(90deg, rgba(255, 215, 0, 0.1) 0%, transparent 100%);
    }

    .rank-2 {
      background: linear-gradient(90deg, rgba(192, 192, 192, 0.1) 0%, transparent 100%);
    }

    .rank-3 {
      background: linear-gradient(90deg, rgba(205, 127, 50, 0.1) 0%, transparent 100%);
    }

    th {
      font-weight: 600;
    }

    .sortable {
      cursor: pointer;
      user-select: none;
      position: relative;
      transition: background-color 0.2s;
    }

    .sortable:hover {
      background: rgba(59, 130, 246, 0.1);
    }

    .sort-indicator {
      margin-left: 4px;
      opacity: 0.5;
      font-size: 0.8em;
    }

    .sort-active {
      opacity: 1;
    }
  </style>
</head>

<body class="bg-gray-50 text-gray-900 antialiased">
  <!-- Header -->
  <header class="sticky top-0 z-30 backdrop-blur bg-white/70 border-b">
    <div class="max-w-6xl mx-auto px-4 py-4 flex items-center justify-between">
      <a href="#" class="font-semibold tracking-tight text-lg">LiveSearchbench</a>
      <nav class="hidden md:flex gap-3 text-sm">
        <a href="#leaderboard" class="px-3 py-1.5 rounded-full bg-gray-800 text-white">Leaderboard</a>
        <a href="#details" class="px-3 py-1.5 rounded-full border">Details</a>
        <a href="https://github.com/hengzzzhou/LiveSearchbench" class="px-3 py-1.5 rounded-full border"
          target="_blank" rel="noopener">Code</a>
      </nav>
    </div>
  </header>

  <!-- Hero -->
  <section class="max-w-6xl mx-auto px-4 pt-14 pb-6">
    <div class="w-full">
      <div class="text-center mb-8">
        <h1 class="text-3xl md:text-4xl font-extrabold leading-tight mb-3">LiveSearchBench: An Automatically Constructed Benchmark for Retrieval and Reasoning over Dynamic Knowledge</h1>
        
        <!-- Authors -->
        <div class="text-sm text-gray-600 mb-4 leading-relaxed max-w-4xl mx-auto">
          <p class="mb-2">
            <span class="font-medium">Heng Zhou</span><sup>1,2,*</sup>, 
            <span class="font-medium">Ao Yu</span><sup>1,*</sup>, 
            <span class="font-medium">Yuchen Fan</span><sup>1,3,*</sup>, 
            <span class="font-medium">Jianing Shi</span><sup>4</sup>, 
            <span class="font-medium">Li Kang</span><sup>1,3</sup>,
          </p>
          <p class="mb-2">
            <span class="font-medium">Hejia Geng</span><sup>5</sup>, 
            <span class="font-medium">Yongting Zhang</span>, 
            <span class="font-medium">Yutao Fan</span><sup>2</sup>, 
            <span class="font-medium">Yuhao Wu</span>, 
            <span class="font-medium">Tiancheng He</span>,
          </p>
          <p class="mb-3">
            <span class="font-medium">Yiran Qin</span><sup>2</sup>, 
            <span class="font-medium">Lei Bai</span><sup>2,â€ </sup>, 
            <span class="font-medium">Zhenfei Yin</span><sup>5,â€ </sup>
          </p>
          <div class="text-xs leading-relaxed">
            <p><sup>1</sup>University of Science and Technology of China <sup>2</sup>Shanghai AI Laboratory</p>
            <p><sup>3</sup>Shanghai Jiao Tong University <sup>4</sup>London School of Economics <sup>5</sup>University of Oxford</p>
            <p class="mt-1"><sup>*</sup>Equal contributions &nbsp;&nbsp; <sup>â€ </sup>Corresponding author</p>
          </div>
        </div>
        
        <h2 class="text-lg text-gray-600 mt-2 mb-6">A lightweight, contaminationâ€‘aware benchmark for realâ€‘time search systems</h2>
        
        <div class="mt-6 flex flex-wrap gap-3 justify-center">
          <a href="#leaderboard" class="px-4 py-2 rounded-xl bg-blue-600 text-white hover:bg-blue-700">Open Leaderboard</a>
          <a href="#details" class="px-4 py-2 rounded-xl border hover:bg-gray-100">Read Details</a>
          <a href="mailto:hengzzzhou@gmail.com" class="px-4 py-2 rounded-xl border hover:bg-gray-100">ðŸ“§ Contact</a>
        </div>
      </div>
      
      <!-- Method Overview Image -->
      <div class="w-full bg-gray-50 border rounded-xl p-8 text-center">
        <img src="pipeline.png" alt="LiveSearchBench Pipeline" class="w-full max-w-4xl mx-auto rounded-lg shadow-lg" />
      </div>
    </div>
  </section>

  <!-- Details / About -->
  <section id="details" class="max-w-6xl mx-auto px-4 py-10">
    <div class="bg-white rounded-2xl p-6 border shadow-sm">
      <h2 class="text-2xl font-bold mb-6 text-center">About</h2>
      
      <!-- Method Overview Diagram -->
      <div class="mb-8 bg-gradient-to-r from-purple-50 to-blue-50 rounded-xl p-6 border">
        <h3 class="text-lg font-semibold mb-4 text-center text-gray-800">LiveSearchBench Pipeline</h3>
        <div class="grid grid-cols-1 md:grid-cols-3 gap-4 text-center">
          <!-- Step 1: Knowledge Delta Extraction -->
          <div class="bg-white rounded-lg p-4 shadow-sm">
            <div class="text-3xl mb-2">ðŸ“Š</div>
            <h4 class="font-semibold text-purple-700 mb-2">Differential Knowledge Extraction</h4>
            <p class="text-sm text-gray-600">Compute deltas between successive Wikidata snapshots to identify new & updated facts</p>
          </div>
          
          <!-- Step 2: Multi-level Question Generation -->
          <div class="bg-white rounded-lg p-4 shadow-sm">
            <div class="text-3xl mb-2">ðŸŽ¯</div>
            <h4 class="font-semibold text-blue-700 mb-2">Multi-level Question Generation</h4>
            <p class="text-sm text-gray-600">Synthesize questions at three difficulty levels: Single-hop, Multi-constraint, Multi-hop+Fuzz</p>
          </div>
          
          <!-- Step 3: SPARQL Validation -->
          <div class="bg-white rounded-lg p-4 shadow-sm">
            <div class="text-3xl mb-2">âœ…</div>
            <h4 class="font-semibold text-green-700 mb-2">SPARQL Validation</h4>
            <p class="text-sm text-gray-600">Ensure each question admits a unique, verifiable answer through automated validation</p>
          </div>
        </div>
      </div>
      
      <p class="text-gray-700 leading-relaxed">Evaluating large language models (LLMs) on question answering often relies on static benchmarks that reward memorization and understate the role of retrieval, failing to capture the dynamic nature of world knowledge. We present <strong>LiveSearchBench</strong>, an automated pipeline for constructing retrieval-dependent benchmarks from recent knowledge updates. Our method computes deltas between successive Wikidata snapshots, filters candidate triples for quality, and synthesizes natural-language questions at three levels of reasoning difficulty, each guaranteed to admit a unique, verifiable answer through SPARQL validation. The pipeline is fully automated, scalable across time, and minimizes human intervention, enabling continual regeneration of temporally grounded benchmarks. Experiments show a pronounced performance drop when models confront facts that post-date pretraining, with the gap most salient on multi-hop queries. Retrieval-augmented methods and larger, instruction-tuned models provide partial gains but fail to close this recency gap. By design, <strong>LiveSearchBench</strong> shifts evaluation from static memorization toward tasks that require up-to-date retrieval and reasoning, offering a foundation for systematic, long-term assessment of LLMs under evolving knowledge.</p>
    </div>
  </section>

  <!-- Leaderboard -->
  <section id="leaderboard" class="max-w-6xl mx-auto px-4 pb-10">
    <div class="flex items-end justify-between">
      <h2 class="text-2xl font-bold">Leaderboard</h2>
    </div>
    
    <!-- Large Models Table -->
    <div class="mt-6">
      <h3 class="text-lg font-semibold mb-3 text-gray-800">Large Language Models</h3>
      <div class="overflow-x-auto bg-white border rounded-2xl p-4 shadow-sm">
        <table class="w-full text-left text-sm striped" id="large-board">
          <thead class="text-gray-500 border-b">
            <tr>
              <th class="py-3 text-left w-20 pr-6">Rank</th>
              <th class="text-left w-1/3 pl-4">Model</th>
              <th class="text-center sortable w-1/6" data-column="level1" data-table="large">
                Level 1<span class="sort-indicator">â†•</span>
              </th>
              <th class="text-center sortable w-1/6" data-column="level2" data-table="large">
                Level 2<span class="sort-indicator">â†•</span>
              </th>
              <th class="text-center sortable w-1/6" data-column="level3" data-table="large">
                Level 3<span class="sort-indicator">â†•</span>
              </th>
              <th class="text-center sortable w-1/6" data-column="avg" data-table="large">
                Average<span class="sort-indicator sort-active">â†“</span>
              </th>
            </tr>
          </thead>
          <tbody></tbody>
        </table>
      </div>
    </div>

    <!-- Small Models with RL Table -->
    <div class="mt-6">
      <h3 class="text-lg font-semibold mb-3 text-gray-800">Small Models with Reinforcement Learning</h3>
      <div class="overflow-x-auto bg-white border rounded-2xl p-4 shadow-sm">
        <table class="w-full text-left text-sm striped" id="small-board">
          <thead class="text-gray-500 border-b">
            <tr>
              <th class="py-3 text-left w-20 pr-6">Rank</th>
              <th class="text-left w-1/3 pl-4">Model</th>
              <th class="text-center sortable w-1/6" data-column="level1" data-table="small">
                Level 1<span class="sort-indicator">â†•</span>
              </th>
              <th class="text-center sortable w-1/6" data-column="level2" data-table="small">
                Level 2<span class="sort-indicator">â†•</span>
              </th>
              <th class="text-center sortable w-1/6" data-column="level3" data-table="small">
                Level 3<span class="sort-indicator">â†•</span>
              </th>
              <th class="text-center sortable w-1/6" data-column="avg" data-table="small">
                Average<span class="sort-indicator sort-active">â†“</span>
              </th>
            </tr>
          </thead>
          <tbody></tbody>
        </table>
      </div>
    </div>
  </section>

  <footer class="border-t">
    <div class="max-w-6xl mx-auto px-4 py-8 text-xs text-gray-500">Â© <span id="year"></span> LiveSearchbench Â· Hosted on
      GitHub Pages</div>
  </footer>

  <script>
    // ===== Large Models Data =====
    const LARGE_MODELS_DATA = {
      runs: [
        { name: 'anthropic/claude-sonnet-4.5', level1: '38.67%', level2: '39.00%', level3: '42.00%', avg: '39.89%' },
        { name: 'gemini-2.5-pro', level1: '33.33%', level2: '51.00%', level3: '42.00%', avg: '42.11%' },
        { name: 'gemini-2.5-flash', level1: '38.00%', level2: '32.00%', level3: '38.00%', avg: '36.00%' },
        { name: 'deepseek-v3.1', level1: '35.33%', level2: '35.00%', level3: '28.00%', avg: '32.78%' },
        { name: 'Pro/deepseek-ai/DeepSeek-R1', level1: '34.67%', level2: '43.00%', level3: '42.00%', avg: '39.89%' },
        { name: 'meta-llama/llama-3.3-70b-instruct', level1: '34.67%', level2: '46.00%', level3: '30.00%', avg: '36.89%' },
        { name: 'moonshotai/kimi-k2', level1: '36.67%', level2: '40.00%', level3: '36.00%', avg: '37.56%' },
        { name: 'gpt-5', level1: '27.33%', level2: '57.00%', level3: '42.00%', avg: '42.11%' },
        { name: 'o3-2025-04-16', level1: '12.00%', level2: '27.00%', level3: '28.00%', avg: '22.33%' },
        { name: 'o3-mini', level1: '12.00%', level2: '19.00%', level3: '14.00%', avg: '15.00%' },
        { name: 'grok-4', level1: '38.00%', level2: '54.00%', level3: '34.00%', avg: '42.00%' },
        { name: 'z-ai/glm-4.6', level1: '36.00%', level2: '35.00%', level3: '28.00%', avg: '33.00%' },
        { name: 'qwen-max', level1: '42.00%', level2: '42.00%', level3: '34.00%', avg: '39.33%' },
        { name: 'Qwen/Qwen3-235B-A22B', level1: '19.33%', level2: '19.00%', level3: '20.00%', avg: '19.44%' }
      ]
    };

    // ===== Small Models with RL Data =====
    const SMALL_MODELS_DATA = {
      runs: [
        { name: 'Qwen2.5-14B-Search-R1', level1: '28.00%', level2: '33.00%', level3: '22.00%', avg: '27.70%' },
        { name: 'Qwen2.5-7B-Search-R1', level1: '27.30%', level2: '29.00%', level3: '18.00%', avg: '24.80%' },
        { name: 'qwen3b-Search-R1', level1: '24.00%', level2: '27.00%', level3: '12.00%', avg: '21.00%' },
        { name: 'llama3b-SSRL', level1: '23.30%', level2: '22.00%', level3: '12.00%', avg: '19.10%' },
        { name: 'llama3b-Search-R1', level1: '25.30%', level2: '21.00%', level3: '10.00%', avg: '18.77%' },
        { name: 'qwen3b-SSRL', level1: '20.00%', level2: '18.00%', level3: '4.00%', avg: '14.00%' }
      ]
    };

    const largeTbody = document.querySelector('#large-board tbody');
    const smallTbody = document.querySelector('#small-board tbody');
    let largeSortState = { column: 'avg', direction: 'desc' };
    let smallSortState = { column: 'avg', direction: 'desc' };

    function parseValue(value, column) {
      if (value === '-') return column === 'name' ? 'zzz' : -1;
      if (column === 'name') return value.toLowerCase();
      return parseFloat(value);
    }

    function sortData(data, column, direction) {
      return [...data].sort((a, b) => {
        const aVal = parseValue(a[column], column);
        const bVal = parseValue(b[column], column);

        if (aVal === bVal) return 0;

        if (column === 'name') {
          return direction === 'asc' ?
            (aVal < bVal ? -1 : 1) :
            (aVal > bVal ? -1 : 1);
        } else {
          // For numeric columns, put -1 (missing data) at the end
          if (aVal === -1 && bVal === -1) return 0;
          if (aVal === -1) return 1;
          if (bVal === -1) return -1;

          return direction === 'desc' ? bVal - aVal : aVal - bVal;
        }
      });
    }

    function updateSortIndicators(tableType, sortState) {
      const tableSelector = tableType === 'large' ? '#large-board' : '#small-board';
      document.querySelectorAll(`${tableSelector} .sort-indicator`).forEach(indicator => {
        indicator.textContent = 'â†•';
        indicator.classList.remove('sort-active');
      });

      const activeHeader = document.querySelector(`${tableSelector} [data-column="${sortState.column}"] .sort-indicator`);
      if (activeHeader) {
        activeHeader.textContent = sortState.direction === 'desc' ? 'â†“' : 'â†‘';
        activeHeader.classList.add('sort-active');
      }
    }

    function renderBoard(list, tbody, sortState) {
      tbody.innerHTML = '';

      list.forEach((row, i) => {
        const tr = document.createElement('tr');
        let rankClass = '';

        // Only highlight top 3 if sorted by average
        if (sortState.column === 'avg' && row.avg !== '-') {
          if (i === 0) rankClass = 'rank-1';
          else if (i === 1) rankClass = 'rank-2';
          else if (i === 2) rankClass = 'rank-3';
        }

        tr.className = rankClass;
        
        // Generate rank display with medals
        let rankDisplay = '';
        if (sortState.column === 'avg' && row.avg !== '-') {
          if (i === 0) rankDisplay = '<span class="text-xl">ðŸ¥‡</span>';
          else if (i === 1) rankDisplay = '<span class="text-xl">ðŸ¥ˆ</span>';
          else if (i === 2) rankDisplay = '<span class="text-xl">ðŸ¥‰</span>';
          else rankDisplay = (i + 1).toString();
        } else {
          rankDisplay = (i + 1).toString();
        }
        
        tr.innerHTML = `<td class="py-3 font-medium pr-6">${rankDisplay}</td>
                          <td class="font-medium pl-4">${row.name}</td>
                          <td class="text-center">${row.level1}</td>
                          <td class="text-center">${row.level2}</td>
                          <td class="text-center">${row.level3}</td>
                          <td class="text-center font-semibold">${row.avg}</td>`;
        tbody.appendChild(tr);
      });
    }

    // Add click handlers for sorting
    document.querySelectorAll('.sortable').forEach(header => {
      header.addEventListener('click', () => {
        const column = header.dataset.column;
        const tableType = header.dataset.table;
        
        let currentSort, data, tbody;
        if (tableType === 'large') {
          currentSort = largeSortState;
          data = LARGE_MODELS_DATA.runs;
          tbody = largeTbody;
        } else {
          currentSort = smallSortState;
          data = SMALL_MODELS_DATA.runs;
          tbody = smallTbody;
        }

        if (currentSort.column === column) {
          currentSort.direction = currentSort.direction === 'desc' ? 'asc' : 'desc';
        } else {
          currentSort.column = column;
          currentSort.direction = 'desc';
        }

        const sortedData = sortData(data, currentSort.column, currentSort.direction);
        updateSortIndicators(tableType, currentSort);
        renderBoard(sortedData, tbody, currentSort);
      });
    });

    // Initial render for both tables
    const initialLargeData = sortData(LARGE_MODELS_DATA.runs, largeSortState.column, largeSortState.direction);
    const initialSmallData = sortData(SMALL_MODELS_DATA.runs, smallSortState.column, smallSortState.direction);
    
    updateSortIndicators('large', largeSortState);
    updateSortIndicators('small', smallSortState);
    renderBoard(initialLargeData, largeTbody, largeSortState);
    renderBoard(initialSmallData, smallTbody, smallSortState);

    document.getElementById('year').textContent = new Date().getFullYear();
  </script>
</body>

</html>